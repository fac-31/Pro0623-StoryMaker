import 'dotenv/config';
import { ChatOpenAI } from '@langchain/openai';
import { PromptTemplate } from '@langchain/core/prompts';
import { json } from '@sveltejs/kit';
import type { UserPrompt } from '$lib/models/UserPrompt.js';

// Import the generated Zod schema
import { slideSchema } from '$lib/schemas/story.schema.js'; // Generated by ts-to-zod

// Use the Zod schema with LangChain
const model = new ChatOpenAI({
	modelName: 'gpt-4o-mini',
	temperature: 0,
	maxTokens: 2000
}).withStructuredOutput(slideSchema);

// Create your prompt template (simplified since JSON structure is enforced)
const promptTemplate = PromptTemplate.fromTemplate(`
Create a detailed slide structure for: {userInput}

Requirements:
- Include specific character descriptions for visual generation
- Provide clear dialogue for each slide
- Describe the visual scene in detail for image generation
- Specify camera angles and visual style

Story style: {storyStyle}
Genre: {genre}
`);

async function generateSlide(userPrompt: UserPrompt) {
	// Format the prompt

	const promptValues = {
		userInput: userPrompt.userInput,
		storyStyle: userPrompt.storyStyle,
		genre: userPrompt.genre
	};

	const formattedPrompt = await promptTemplate.format(promptValues);
	// Call the model - it will return structured JSON automatically
	const result = await model.invoke(formattedPrompt);
	return result; // This is guaranteed to be valid JSON matching your schema
}

export async function POST({ request }) {
	const userPrompt: UserPrompt = await request.json();
	const response = await generateSlide(userPrompt);
	return json(response);
}

// How we might add langgraph
/*
    -import { json } from '@sveltejs/kit';
    -import { ChatOpenAI } from '@langchain/openai';
    -import { initializeAgentExecutorWithOptions } from 'langchain/agents';
    -import { traceable } from 'langsmith/traceable';
    -import { TavilySearch } from '@langchain/tavily';
    -import 'dotenv/config';
    +import { json } from '@sveltejs/kit';
    +import { ChatOpenAI } from '@langchain/openai';
    +import { traceable } from 'langsmith/traceable';
    +import { TavilySearch } from '@langchain/tavily';
    +import { Graph } from '@langchain/langgraph';
    +import 'dotenv/config';
    @@ 8,33c9, Thirty‑something
    -const handler = traceable(
    -  async function ({ prompt }: { prompt: string }) {
    -    const model = new ChatOpenAI({
    -      openAIApiKey: process.env.OPENAI_API_KEY,
    -      modelName: 'gpt-4o-mini',
    -      temperature: 0,
    -      maxTokens: 256,
    -    });
    -
    -    const tool = new TavilySearch({
    -      maxResults: 5,
    -    });
    -
    -    const executor = await initializeAgentExecutorWithOptions([tool], model, {
    -      agentType: 'openai-functions',
    -      verbose: true,
    -    });
    -
    -    const result = await executor.call({ input: prompt });
    -
    -    return { result };
    -  },
    -  {
    -    name: 'SvelteKit LangChain Agent Handler',
    -  }
    -);
    +const handler = traceable(
    +  async function ({ prompt }: { prompt: string }) {
    +    // ——————————————————————————
    +    // (A) Setup the underlying LLM & Tool
    +    // ——————————————————————————
    +    const model = new ChatOpenAI({
    +      openAIApiKey: process.env.OPENAI_API_KEY,
    +      modelName: 'gpt-4o-mini',
    +      temperature: 0,
    +      maxTokens: 256,
    +    });
    +    const tool = new TavilySearch({ maxResults: 5 });
    +
    +    // ——————————————————————————
    +    // (B) Build a tiny Graph workflow
    +    // ——————————————————————————
    +    const graph = new Graph({ name: 'LangGraph-Agent' });
    +
    +    // 1️⃣ start node: just forwards the prompt
    +    const start = graph.addNode('start', {
    +      fn: async ({ input }: { input: string }) => input
    +    });
    +
    +    // 2️⃣ search node: calls our TavilySearch tool
    +    const searchNode = graph.addNode('web_search', {
    +      fn: async ({ input }: { input: string }) =>
    +        tool.call({ input })
    +    });
    +
    +    // 3️⃣ llm node: calls the ChatOpenAI model
    +    const llmNode = graph.addNode('generate', {
    +      fn: async ({ input }: { input: string }) =>
    +        model.call([
    +          { role: 'system', content: 'You are a helpful assistant.' },
    +          { role: 'user', content: input }
    +        ])
    +    });
    +
    +    // Wire them together: start → search → llm
    +    graph.addEdge(start, searchNode);
    +    graph.addEdge(searchNode, llmNode);
    +
    +    // Execute the graph end‑to‑end
    +    const result = await graph.execute({ input: prompt });
    +    return { result };
    +  },
    +  { name: 'SvelteKit LangGraph Agent Handler' }
    +);
*/
